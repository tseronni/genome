{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:23:56.980112900Z",
     "start_time": "2023-08-30T19:23:55.540865100Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from src.utils.UsefulPaths import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "paths = Paths()\n",
    "\n",
    "with open(paths.json_subsectors, 'r') as file:\n",
    "    subsectors = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:23:56.996227600Z",
     "start_time": "2023-08-30T19:23:56.983148400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_abstract = pd.read_parquet(paths.raw_parquet_abstract)\n",
    "\n",
    "offset_div = 50\n",
    "df_joao = df_abstract.iloc[:offset_div].copy().reset_index(drop='index')\n",
    "df_leo = df_abstract.iloc[offset_div:offset_div*2].copy().reset_index(drop='index')\n",
    "df_maxm = df_abstract.iloc[offset_div*2:offset_div*3].copy().reset_index(drop='index')\n",
    "df_rafael = df_abstract.iloc[offset_div*4:offset_div*5].copy().reset_index(drop='index')\n",
    "df_thiago = df_abstract.iloc[offset_div*6:offset_div*7].copy().reset_index(drop='index')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:25:28.055201100Z",
     "start_time": "2023-08-30T19:25:21.930255500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class PatentSimilarity:\n",
    "    def __init__(self,\n",
    "                 df_patents: pd.DataFrame = pd.DataFrame(),\n",
    "                 model_name: str = 'bert-base-uncased',\n",
    "                 definition_weight: float = 1,\n",
    "                 keywords_weight: float = 1,\n",
    "                 does_include: float = 1,\n",
    "                 does_not_include: float = -1,\n",
    "                 show_progress_bar=False):\n",
    "\n",
    "        self.df_patents = df_patents\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "        # Peso para a definição\n",
    "        self.definition_weight = definition_weight\n",
    "\n",
    "        # Peso para as keywords\n",
    "        self.keywords_weight = keywords_weight\n",
    "\n",
    "        # Peso para as Does Include\n",
    "        self.does_include = does_include\n",
    "\n",
    "        # Peso para as Does Not Include\n",
    "        self.does_not_include = does_not_include\n",
    "\n",
    "        self.show_progress_bar = show_progress_bar\n",
    "\n",
    "        self.subsetors_embeddings = {}\n",
    "        for subsetor_name, subsetor_values in subsectors.items():\n",
    "\n",
    "            subsetor_definition = subsetor_values.get('Definition', '')\n",
    "            subsetor_keywords = subsetor_values.get('Keywords', '')\n",
    "            subsetor_does_include = subsetor_values.get('Does include', '')\n",
    "            subsetor_does_not_include = subsetor_values.get('Does not include', '')\n",
    "\n",
    "            subsetor_definition_emb = self.model.encode(subsetor_definition, convert_to_tensor=True, show_progress_bar=self.show_progress_bar) * self.definition_weight\n",
    "            subsetor_keywords_emb = self.model.encode(subsetor_keywords, convert_to_tensor=True, show_progress_bar=self.show_progress_bar) * self.keywords_weight\n",
    "            subsetor_does_include_emb = self.model.encode(subsetor_does_include, convert_to_tensor=True, show_progress_bar=self.show_progress_bar) * self.does_include\n",
    "            subsetor_does_not_include_emb = self.model.encode(subsetor_does_not_include, convert_to_tensor=True, show_progress_bar=self.show_progress_bar) * self.does_not_include\n",
    "\n",
    "            self.subsetors_embeddings[subsetor_name] = [subsetor_definition_emb, subsetor_keywords_emb, subsetor_does_include_emb, subsetor_does_not_include_emb]\n",
    "\n",
    "    def similarity_between_one_patent_with_one_subsetor(self, patent_abstract, subsetor_name):\n",
    "\n",
    "        # We pass the convert_to_tensor=True parameter to the encode function. This will return a pytorch tensor containing our embeddings. We can then call util.cos_sim(A, B) which computes the cosine similarity between all vectors in A and all vectors in B.\n",
    "        patent_abstract_emb = self.model.encode(patent_abstract, convert_to_tensor=True, show_progress_bar=self.show_progress_bar)\n",
    "\n",
    "        subsetor_definition_emb = self.subsetors_embeddings[subsetor_name][0]\n",
    "        subsetor_keywords_emb = self.subsetors_embeddings[subsetor_name][1]\n",
    "        subsetor_does_include_emb = self.subsetors_embeddings[subsetor_name][2]\n",
    "        subsetor_does_not_include_emb = self.subsetors_embeddings[subsetor_name][3]\n",
    "\n",
    "        # Combine os embeddings\n",
    "        combined_emb = subsetor_definition_emb + subsetor_keywords_emb + subsetor_does_include_emb + subsetor_does_not_include_emb\n",
    "\n",
    "        similarity = util.cos_sim(patent_abstract_emb, combined_emb).item()\n",
    "\n",
    "        # similarity = util.cos_sim(patent_abstract_emb, subsetor_definition_emb).item()\n",
    "\n",
    "        return similarity\n",
    "\n",
    "    def similarity_between_one_patent_with_all_subsetors(self, publication_number, patent_abstract):\n",
    "        col_names = ['publication_number', 'patent_abstract']\n",
    "        patents_similarities = [publication_number, patent_abstract]\n",
    "        for subsetor_name, embeddings in self.subsetors_embeddings.items():\n",
    "            col_names.append(subsetor_name)\n",
    "            specific_sim  = self.similarity_between_one_patent_with_one_subsetor(patent_abstract, subsetor_name)\n",
    "            patents_similarities.append(specific_sim)\n",
    "\n",
    "        df_one_patent = pd.DataFrame([patents_similarities], columns=col_names)\n",
    "        return df_one_patent\n",
    "\n",
    "    def similarity_between_all_patents_with_all_subsetors(self, break_index=-1):\n",
    "        df_all = pd.DataFrame()\n",
    "        for index, row in self.df_patents.iterrows():\n",
    "            row_sim = self.similarity_between_one_patent_with_all_subsetors(row['publication_number'], row['abstract'])\n",
    "            df_all = pd.concat([df_all, row_sim])\n",
    "            if break_index == index:\n",
    "                break\n",
    "\n",
    "        df_all['score_max'] = df_all.iloc[: , 2:].max(axis=1)\n",
    "        df_all['score_name'] = df_all.iloc[: , 2:].idxmax(axis=1)\n",
    "\n",
    "        return df_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T21:14:54.653011900Z",
     "start_time": "2023-08-30T21:14:54.637300300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 18:14:57,745 - INFO - Load pretrained SentenceTransformer: bert-base-multilingual-cased\n",
      "2023-08-30 18:14:57,745 - DEBUG - Resetting dropped connection: huggingface.co\n",
      "2023-08-30 18:14:58,104 - DEBUG - https://huggingface.co:443 \"GET /api/models/bert-base-multilingual-cased HTTP/1.1\" 200 4337\n",
      "2023-08-30 18:14:58,268 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/.gitattributes HTTP/1.1\" 200 0\n",
      "2023-08-30 18:14:58,432 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/README.md HTTP/1.1\" 200 0\n",
      "2023-08-30 18:14:58,589 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json HTTP/1.1\" 200 0\n",
      "2023-08-30 18:14:58,762 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/model.safetensors HTTP/1.1\" 302 0\n",
      "2023-08-30 18:14:58,933 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "2023-08-30 18:14:59,104 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer.json HTTP/1.1\" 200 0\n",
      "2023-08-30 18:14:59,277 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2023-08-30 18:14:59,434 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-multilingual-cased/resolve/fdfce55e83dbed325647a63e7e1f5de19f0382ba/vocab.txt HTTP/1.1\" 200 0\n",
      "2023-08-30 18:14:59,444 - WARNING - No sentence-transformers model found with name C:\\Users\\thiag/.cache\\torch\\sentence_transformers\\bert-base-multilingual-cased. Creating a new one with MEAN pooling.\n",
      "2023-08-30 18:15:00,155 - INFO - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# bert-large-uncased-whole-word-masking\n",
    "# bert-base-multilingual-cased\n",
    "bert_sim = PatentSimilarity(df_patents=df_thiago, model_name='bert-base-multilingual-cased', does_include=2, does_not_include=-2)\n",
    "df_all_sim = bert_sim.similarity_between_all_patents_with_all_subsetors(break_index=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T21:15:05.643840500Z",
     "start_time": "2023-08-30T21:14:57.745681200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "   publication_number                                    patent_abstract  \\\n0         20080017043  A brew stick for brewing a measure of brewable...   \n0         20080050603  Polylactide polymers are reacted with an epoxy...   \n0         20080007823  An interferometer comprises a light source uni...   \n\n      score_name  score_max  \n0  Industry 4.0    0.650784  \n0     Blockchain   0.612674  \n0  Industry 4.0    0.646756  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>publication_number</th>\n      <th>patent_abstract</th>\n      <th>score_name</th>\n      <th>score_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20080017043</td>\n      <td>A brew stick for brewing a measure of brewable...</td>\n      <td>Industry 4.0</td>\n      <td>0.650784</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>20080050603</td>\n      <td>Polylactide polymers are reacted with an epoxy...</td>\n      <td>Blockchain</td>\n      <td>0.612674</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>20080007823</td>\n      <td>An interferometer comprises a light source uni...</td>\n      <td>Industry 4.0</td>\n      <td>0.646756</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sim[['publication_number', 'patent_abstract', 'score_name', 'score_max']].head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T21:15:06.881250200Z",
     "start_time": "2023-08-30T21:15:06.863831800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A brew stick for brewing a measure of brewable material. The brew stick may include a bag with the measure of brewable material positioned therein and a plate. The plate may include a pair of wings and a central tab. The bag is connected to the central tab such that the bag can be raised within the wings.\n",
      "\n",
      "Industry 4.0 \n",
      "0.6507836580276489\n",
      "\n",
      "\n",
      "Polylactide polymers are reacted with an epoxy-functional acrylate polymer to introduce long-chain branching into the polymer. The acrylate polymer provides a flexible means for introducing a controllable amount of branching into the polylactide polymer, with little risk of forming gelled or highly crosslinked structures. The branched polylactide polymers have excellent melt rheological properties that make them more easily processable in various melt-processing applications.\n",
      "\n",
      "Blockchain\n",
      "0.6126735806465149\n",
      "\n",
      "\n",
      "An interferometer comprises a light source unit, a first splitter, a reference beam unit and a detection unit. The light source unit provides a laser beam. The first splitter receives the laser beam from the light source unit and splits the laser beam into a first beam and a second beam. The reference beam unit comprises a frequency shifter, a stopper and a spherical mirror. A center of the frequency shifter is located on a curvature center of the spherical mirror, the first beam traveling from the first splitter to the frequency shifter, the frequency shifter splitting the first beam into a diffraction beam and a zero-order beam, wherein the diffraction beam travels to the spherical mirror, reflected by the spherical mirror toward the frequency shifter, passing the frequency shifter to become a reference beam, and the zero-order beam is stopped by the stopper. The detection unit receives the reference beam from the reference beam unit.\n",
      "\n",
      "Industry 4.0 \n",
      "0.646755576133728\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_all_sim.iterrows():\n",
    "    print(f'{row[\"patent_abstract\"]}\\n\\n{row[\"score_name\"]}\\n{row[\"score_max\"]}\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T21:15:08.237393500Z",
     "start_time": "2023-08-30T21:15:08.221765600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
