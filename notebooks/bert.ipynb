{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-29T01:09:42.073150200Z",
     "start_time": "2023-08-29T01:09:42.073150200Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from src.utils.UsefulPaths import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "class BertSimilarity:\n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = TFBertModel.from_pretrained(model_name)\n",
    "        self.model.trainable = False\n",
    "\n",
    "        # Peso para as keywords\n",
    "        self.keyword_weight = 1.0\n",
    "\n",
    "        # Peso para as non-keywords\n",
    "        self.non_keyword_weight = -2\n",
    "\n",
    "    def encode(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=8000)\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs['pooler_output']\n",
    "\n",
    "    def encode_with_keywords(self, text, keywords, non_keywords):\n",
    "        # Encode texto principal\n",
    "        emb_text = self.encode(text)\n",
    "\n",
    "        # Encode keywords e non-keywords e ponder√°-los\n",
    "        emb_keywords = self.encode(keywords) * self.keyword_weight\n",
    "        emb_non_keywords = self.encode(non_keywords) * self.non_keyword_weight\n",
    "\n",
    "        # Combine os embeddings\n",
    "        combined_emb = emb_text + emb_keywords + emb_non_keywords\n",
    "        return combined_emb\n",
    "\n",
    "    def compute_similarity(self, patent_abstract, subsetor_definiton, subsetor_keywords, subsetor_non_keywords):\n",
    "        patent_embbedings = self.encode_with_keywords(patent_abstract, subsetor_keywords, subsetor_non_keywords)\n",
    "        subsetor_embeddings = self.encode(subsetor_definiton)\n",
    "\n",
    "        sim = cosine_similarity(patent_embbedings, subsetor_embeddings)\n",
    "\n",
    "        return sim[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T01:09:42.891317900Z",
     "start_time": "2023-08-29T01:09:42.875692300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "paths = Paths()\n",
    "\n",
    "with open(paths.json_subsectors, 'r') as file:\n",
    "    subsectors = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T01:09:44.243577800Z",
     "start_time": "2023-08-29T01:09:44.227455700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 22:14:48,066 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
      "2023-08-28 22:14:48,244 - DEBUG - https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medtech / Medical devices: 0.9704\n",
      "New Food: 0.9600\n",
      "Adtech : 0.9503\n",
      "Cleantech: 0.9239\n",
      "Gaming (Digital Media Sub-Cluster): 0.8923\n",
      "Artificial Intelligence, Big Data and Analytics: 0.8914\n",
      "Blockchain: 0.8861\n",
      "Biopharma / Biotech: 0.8838\n",
      "Advanced Manufacturing and Robotics: 0.8763\n",
      "AR / VR (Digital Media Sub-Cluster): 0.8689\n",
      "Blue Economy: 0.8612\n",
      "Cybersecurity: 0.8547\n",
      "Industry 4.0 : 0.8425\n",
      "Fintech: 0.7707\n",
      "Digital Media: 0.7660\n",
      "Agtech: 0.4277\n",
      "Edtech: -0.0940\n"
     ]
    }
   ],
   "source": [
    "# 20080063564\n",
    "patent_1 = 'A holographic optical accessing system includes a light source for emitting a light beam; an optical assembly module for receiving the light beam and generating a signal beam and a reference beam that are parallel to each other rather than overlap with each other, and have the same first polarization state; a lens module for focusing the signal beam and the reference beam on a focal point at the same time; and a storage medium for recording the focal point. The optical assembly module includes at least a data plane for displaying image information so that the signal beam contains the image information.'\n",
    "\n",
    "# 20080015942\n",
    "patent_2 = 'A product sampling and recommendation system uses customer profile data and/or real-time information from a point-of-sale system to tailor specific product recommendations to a customer using a sampling station.'\n",
    "\n",
    "# 20080035176\n",
    "patent_3 = 'The present invention relates to a mobile or stationary waste container cleaning system used for residential, commercial and industrial waste, garbage, trash, storage or operations containers or receptacles. Other applications include, but are not limited to cleaning of chemical drums, grease dumpsters (e.g. behind restaurants), rain barrels and non-uniform residential, commercial or industrial dumpsters or waste containers. The container cleaning system can alternatively be used for rural areas, farms or ranches.'\n",
    "\n",
    "bert_sim = BertSimilarity()\n",
    "\n",
    "patent = patent_1\n",
    "sim_dict = {}\n",
    "for key, value in subsectors.items():\n",
    "\n",
    "    subsector_definition = value.get('Definition', '')\n",
    "    subsector_keywords = value.get('Keywords', '')\n",
    "    subsector_does_not_include = value.get('Does not include', '')\n",
    "    subsector_does_include = value.get('Does include', '')\n",
    "\n",
    "    pt_sub_sim = bert_sim.compute_similarity(patent, subsector_definition, subsector_keywords, subsector_does_not_include)\n",
    "    sim_dict[key] = pt_sub_sim\n",
    "\n",
    "sorted_data = dict(sorted(sim_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "for key, value in sorted_data.items():\n",
    "    print(f'{key}: {value:.4f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T01:14:58.427340600Z",
     "start_time": "2023-08-29T01:14:47.904571900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
