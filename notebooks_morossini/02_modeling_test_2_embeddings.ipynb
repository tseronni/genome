{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. OBJECTIVE\n",
    "Classify patents into predefined subsectors based on their abstracts. Any patent that doesn't fit these subsectors will be classified as \"Other.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. DATA\n",
    "2.1 Subsector definitions: json file containing definitions and keyworkds\n",
    "2.2 Patents: csv file containing patent abstracts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:05.963719Z",
     "start_time": "2023-08-29T22:14:05.694546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "raw_data_dir = os.path.join('..', 'data', 'raw')\n",
    "parquet_filename = 'abstract.parquet'\n",
    "parquet_path = os.path.join(raw_data_dir, parquet_filename)\n",
    "df_abstract = pd.read_parquet(parquet_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:21:23.423943Z",
     "start_time": "2023-08-29T22:20:51.817135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   publication_number                                           abstract\n0         20080063564  Embodiments of techniques for determining the ...\n1         20080025285  A method for supporting frequency hopping of a...\n2         20080056857  To correct any positional misalignment of a su...\n3         20080031117  A holographic optical accessing system include...\n4         20080056179  Transmitting an acknowledgement/negative ackno...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>publication_number</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20080063564</td>\n      <td>Embodiments of techniques for determining the ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20080025285</td>\n      <td>A method for supporting frequency hopping of a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20080056857</td>\n      <td>To correct any positional misalignment of a su...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20080031117</td>\n      <td>A holographic optical accessing system include...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20080056179</td>\n      <td>Transmitting an acknowledgement/negative ackno...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstract.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:36.981533Z",
     "start_time": "2023-08-29T22:14:36.839998Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. DATA SPLITTING\n",
    "Not necessary at this point. We will split the data into train and test sets later on, after validating the approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. DATA EXPLORATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,184,916\n"
     ]
    }
   ],
   "source": [
    "# Counting unique publication numbers\n",
    "print('{:,}'.format(df_abstract['publication_number'].nunique()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:37.730759Z",
     "start_time": "2023-08-29T22:14:36.971792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min characters:  1\n",
      "Max characters:  11164\n",
      "Mean characters:  674.0\n"
     ]
    }
   ],
   "source": [
    "# Min, max and mean number of characters in abstracts\n",
    "print('Min characters: ', df_abstract['abstract'].str.len().min())\n",
    "print('Max characters: ', df_abstract['abstract'].str.len().max())\n",
    "print('Mean characters: ', round(df_abstract['abstract'].str.len().mean(),0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:48.600741Z",
     "start_time": "2023-08-29T22:14:41.613349Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "         publication_number    abstract\n421554          20090232753      [A gel\n426571          20090217796     [A soft\n909470          20110045983      [A gel\n986260          20110171940   [A system\n1033571         20110190260         [[1\n1213859         20120178063   [A simple\n1700660         20130306496           A\n1907863         20140161655     A pump.\n2441796         20160011399  [A compact\n2498631         20160078481       [Laws\n2542119         20160154215  [A compact\n2610655         20160144869  [The lever\n2928926         20170216285  [Compounds\n3258131         20180072137   [A single\n3845879         20200097832   [A system\n3884425         20200097716    [Methods",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>publication_number</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>421554</th>\n      <td>20090232753</td>\n      <td>[A gel</td>\n    </tr>\n    <tr>\n      <th>426571</th>\n      <td>20090217796</td>\n      <td>[A soft</td>\n    </tr>\n    <tr>\n      <th>909470</th>\n      <td>20110045983</td>\n      <td>[A gel</td>\n    </tr>\n    <tr>\n      <th>986260</th>\n      <td>20110171940</td>\n      <td>[A system</td>\n    </tr>\n    <tr>\n      <th>1033571</th>\n      <td>20110190260</td>\n      <td>[[1</td>\n    </tr>\n    <tr>\n      <th>1213859</th>\n      <td>20120178063</td>\n      <td>[A simple</td>\n    </tr>\n    <tr>\n      <th>1700660</th>\n      <td>20130306496</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1907863</th>\n      <td>20140161655</td>\n      <td>A pump.</td>\n    </tr>\n    <tr>\n      <th>2441796</th>\n      <td>20160011399</td>\n      <td>[A compact</td>\n    </tr>\n    <tr>\n      <th>2498631</th>\n      <td>20160078481</td>\n      <td>[Laws</td>\n    </tr>\n    <tr>\n      <th>2542119</th>\n      <td>20160154215</td>\n      <td>[A compact</td>\n    </tr>\n    <tr>\n      <th>2610655</th>\n      <td>20160144869</td>\n      <td>[The lever</td>\n    </tr>\n    <tr>\n      <th>2928926</th>\n      <td>20170216285</td>\n      <td>[Compounds</td>\n    </tr>\n    <tr>\n      <th>3258131</th>\n      <td>20180072137</td>\n      <td>[A single</td>\n    </tr>\n    <tr>\n      <th>3845879</th>\n      <td>20200097832</td>\n      <td>[A system</td>\n    </tr>\n    <tr>\n      <th>3884425</th>\n      <td>20200097716</td>\n      <td>[Methods</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the abstracts with 20 or less characters\n",
    "df_abstract[df_abstract['abstract'].str.len() <= 10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:51.002936Z",
     "start_time": "2023-08-29T22:14:48.601926Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. ALGORITHMS\n",
    "- Word embeddings\n",
    "- Similarity measures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "abstract_sample = df_abstract.iloc[0:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:56.555279Z",
     "start_time": "2023-08-29T22:14:56.546163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 2)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_sample.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:14:58.076568Z",
     "start_time": "2023-08-29T22:14:58.066501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:12:27.872516Z",
     "start_time": "2023-08-29T22:12:23.185298Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publication_number                                           abstract\n",
      "0         20080063564  Embodiments of techniques for determining the ...\n",
      "1         20080025285  A method for supporting frequency hopping of a...\n",
      "2         20080056857  To correct any positional misalignment of a su...\n",
      "3         20080031117  A holographic optical accessing system include...\n",
      "4         20080056179  Transmitting an acknowledgement/negative ackno...\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "print(abstract_sample.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:24:55.237878Z",
     "start_time": "2023-08-29T22:24:55.232390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "processed_data_dir = os.path.join('..', 'data', 'processed')\n",
    "json_filename = 'subsector_definitions_adjusted2.json'\n",
    "json_path = os.path.join(processed_data_dir, json_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:23:39.167410Z",
     "start_time": "2023-08-29T22:23:39.162247Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/subsector_definitions_adjusted2.json\n"
     ]
    }
   ],
   "source": [
    "print(json_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:23:40.424093Z",
     "start_time": "2023-08-29T22:23:40.419683Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Load JSON\n",
    "with open(json_path, 'r') as f:\n",
    "    subsectors = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:31:31.527017Z",
     "start_time": "2023-08-29T22:31:31.515741Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "abstract_sample['tokenized_abstract'] = abstract_sample['abstract'].apply(lambda x: x.split())\n",
    "\n",
    "# Tokenize subsector descriptions\n",
    "for subsector in subsectors:\n",
    "    subsector['tokenized_description'] = subsector['description'].split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "all_text = abstract_sample['tokenized_abstract'].tolist() + [sub['tokenized_description'] for sub in subsectors]\n",
    "model = Word2Vec(sentences=all_text, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:31:43.022930Z",
     "start_time": "2023-08-29T22:31:42.893173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    if n_words:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector\n",
    "\n",
    "# Calculate average vectors for each abstract and subsector\n",
    "abstract_sample['avg_vector'] = abstract_sample['tokenized_abstract'].apply(lambda x: average_word_vectors(x, model, 100))\n",
    "subsector_vectors = [average_word_vectors(sub['tokenized_description'], model, 100) for sub in subsectors]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:31:51.466285Z",
     "start_time": "2023-08-29T22:31:51.420707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    publication_number        AI  Robotics  Cleantech   Fintech  Blockchain  \\\n",
      "0          20080063564  0.999708  0.999530   0.999727  0.999607    0.999737   \n",
      "1          20080025285  0.999783  0.999627   0.999779  0.999632    0.999847   \n",
      "2          20080056857  0.999758  0.999596   0.999761  0.999620    0.999790   \n",
      "3          20080031117  0.999802  0.999641   0.999799  0.999630    0.999832   \n",
      "4          20080056179  0.999790  0.999598   0.999813  0.999638    0.999798   \n",
      "..                 ...       ...       ...        ...       ...         ...   \n",
      "95         20080018144  0.999755  0.999646   0.999778  0.999612    0.999759   \n",
      "96         20080011049  0.999814  0.999648   0.999816  0.999652    0.999824   \n",
      "97         20080069132  0.999831  0.999608   0.999839  0.999631    0.999811   \n",
      "98         20080008627  0.999807  0.999625   0.999822  0.999663    0.999822   \n",
      "99         20080011128  0.999775  0.999638   0.999803  0.999664    0.999806   \n",
      "\n",
      "    Cybersecurity Primary Subsector  \n",
      "0        0.999478        Blockchain  \n",
      "1        0.999489        Blockchain  \n",
      "2        0.999490        Blockchain  \n",
      "3        0.999539        Blockchain  \n",
      "4        0.999536         Cleantech  \n",
      "..            ...               ...  \n",
      "95       0.999505         Cleantech  \n",
      "96       0.999560        Blockchain  \n",
      "97       0.999582         Cleantech  \n",
      "98       0.999524         Cleantech  \n",
      "99       0.999528        Blockchain  \n",
      "\n",
      "[100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = []\n",
    "for index, row in abstract_sample.iterrows():\n",
    "    similarities = cosine_similarity([row['avg_vector']], subsector_vectors)[0]\n",
    "    primary_subsector = np.argmax(similarities)\n",
    "    if similarities[primary_subsector] >= 0.6:\n",
    "        primary_subsector = subsectors[primary_subsector]['subsector']\n",
    "    else:\n",
    "        primary_subsector = 'None'\n",
    "    similarity_matrix.append([row['publication_number']] + list(similarities) + [primary_subsector])\n",
    "\n",
    "# Create DataFrame for similarity matrix\n",
    "columns = ['publication_number'] + [sub['subsector_short'] for sub in subsectors] + ['Primary Subsector']\n",
    "similarity_df = pd.DataFrame(similarity_matrix, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "# similarity_df.to_csv('similarity_matrix.csv', index=False)\n",
    "\n",
    "print(similarity_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:31:53.547294Z",
     "start_time": "2023-08-29T22:31:53.451053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def normalize_vector(vec):\n",
    "    return vec / np.linalg.norm(vec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T22:43:09.407859Z",
     "start_time": "2023-08-29T22:43:09.382276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
